{"cells":[{"cell_type":"code","execution_count":178,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-08T17:18:56.905686Z","iopub.status.busy":"2024-08-08T17:18:56.905298Z","iopub.status.idle":"2024-08-08T17:18:56.913050Z","shell.execute_reply":"2024-08-08T17:18:56.911964Z","shell.execute_reply.started":"2024-08-08T17:18:56.905650Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/digit-recognizer/sample_submission.csv\n","/kaggle/input/digit-recognizer/train.csv\n","/kaggle/input/digit-recognizer/test.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import pickle\n","from sklearn.model_selection import train_test_split \n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":179,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:18:56.915107Z","iopub.status.busy":"2024-08-08T17:18:56.914743Z","iopub.status.idle":"2024-08-08T17:19:00.310736Z","shell.execute_reply":"2024-08-08T17:19:00.309494Z","shell.execute_reply.started":"2024-08-08T17:18:56.915076Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ImageId</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27995</th>\n","      <td>27996</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>27996</th>\n","      <td>27997</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>27997</th>\n","      <td>27998</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>27998</th>\n","      <td>27999</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>27999</th>\n","      <td>28000</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>28000 rows × 2 columns</p>\n","</div>"],"text/plain":["       ImageId  Label\n","0            1      0\n","1            2      0\n","2            3      0\n","3            4      0\n","4            5      0\n","...        ...    ...\n","27995    27996      0\n","27996    27997      0\n","27997    27998      0\n","27998    27999      0\n","27999    28000      0\n","\n","[28000 rows x 2 columns]"]},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n","test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n","submission=pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')\n","submission"]},{"cell_type":"code","execution_count":180,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:19:00.313066Z","iopub.status.busy":"2024-08-08T17:19:00.312704Z","iopub.status.idle":"2024-08-08T17:19:00.794217Z","shell.execute_reply":"2024-08-08T17:19:00.793067Z","shell.execute_reply.started":"2024-08-08T17:19:00.313033Z"},"trusted":true},"outputs":[],"source":["y=train[\"label\"].to_numpy()\n","x=train.drop(columns=['label']).to_numpy()\n","x_train, x_test, y_train, y_test = train_test_split(\n","    x, y, test_size=0.20, random_state=0)"]},{"cell_type":"code","execution_count":181,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:19:00.796150Z","iopub.status.busy":"2024-08-08T17:19:00.795660Z","iopub.status.idle":"2024-08-08T17:19:00.805011Z","shell.execute_reply":"2024-08-08T17:19:00.803769Z","shell.execute_reply.started":"2024-08-08T17:19:00.796113Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","class Linear:\n","    def __init__(self, input_dim, output_dim):\n","        \n","        self.W = np.random.randn(input_dim, output_dim) * 0.01\n","        self.b = np.zeros((1, output_dim))\n","\n","    def forward(self, X):\n","        self.X = X\n","        return np.dot(X, self.W) + self.b\n","\n","    def backward(self, dA):\n","        m = self.X.shape[0]\n","        self.dW = np.dot(self.X.T, dA) / m\n","        self.db = np.sum(dA, axis=0, keepdims=True) / m\n","        return  np.dot(dA, self.W.T)"]},{"cell_type":"code","execution_count":182,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:19:00.808910Z","iopub.status.busy":"2024-08-08T17:19:00.808015Z","iopub.status.idle":"2024-08-08T17:19:00.815966Z","shell.execute_reply":"2024-08-08T17:19:00.814861Z","shell.execute_reply.started":"2024-08-08T17:19:00.808868Z"},"trusted":true},"outputs":[],"source":["class ReLU:\n","    def forward(self, X):\n","        self.X = X\n","        \n","        return np.maximum(0, X)\n","\n","    def backward(self, dA):\n","        dX = dA.copy()\n","        dX[self.X <= 0] = 0\n","        return dX\n"]},{"cell_type":"code","execution_count":183,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:19:00.817728Z","iopub.status.busy":"2024-08-08T17:19:00.817324Z","iopub.status.idle":"2024-08-08T17:19:00.827866Z","shell.execute_reply":"2024-08-08T17:19:00.826739Z","shell.execute_reply.started":"2024-08-08T17:19:00.817691Z"},"trusted":true},"outputs":[],"source":["class Sigmoid:\n","    def forward(self, X):\n","        self.A = 1 / (1 + np.exp(-X))\n","        return self.A\n","\n","    def backward(self, dA):\n","        \n","        return dA * self.A * (1 - self.A)\n"]},{"cell_type":"code","execution_count":184,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:19:00.829878Z","iopub.status.busy":"2024-08-08T17:19:00.829449Z","iopub.status.idle":"2024-08-08T17:19:00.842451Z","shell.execute_reply":"2024-08-08T17:19:00.841453Z","shell.execute_reply.started":"2024-08-08T17:19:00.829843Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","class Softmax:\n","    def forward(self, inputs):\n","        \"\"\"\n","        Perform the forward pass of the Softmax activation function.\n","\n","        Args:\n","            inputs (np.ndarray): Input data of shape (batch_size, num_classes).\n","\n","        Returns:\n","            np.ndarray: Output data after applying the Softmax activation function, of the same shape as the input.\n","        \"\"\"\n","        # Compute exponentiated values, with numerical stability\n","        exp_inputs = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n","        # normalize by the sum of all the exp values\n","        self.outputs = exp_inputs / np.sum(exp_inputs, axis=1, keepdims=True)\n","        return self.outputs\n","\n","    def backward(self, d_outputs):\n","        \"\"\"\n","        Perform the backward pass of the Softmax activation function to compute gradients.\n","\n","        Args:\n","            d_outputs (np.ndarray): Gradient of the loss with respect to the output of this layer, of shape (batch_size, num_classes).\n","\n","        Returns:\n","            np.ndarray: Gradient of the loss with respect to the input of this layer, of the same shape as the input.\n","        \"\"\"\n","        batch_size = self.outputs.shape[0]\n","        num_classes = self.outputs.shape[1]\n","\n","        # Initialize gradient of the input\n","        d_inputs = np.zeros_like(d_outputs)\n","\n","        # Compute gradients for each sample in the batch\n","        for i in range(batch_size):\n","            single_output = self.outputs[i].reshape(-1, 1)\n","            single_grad_output = d_outputs[i]\n","\n","            # Jacobian matrix for the softmax function\n","            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n","            # Compute gradient for the current sample\n","            d_inputs[i] = np.dot(jacobian_matrix, single_grad_output)\n","\n","        return d_inputs\n"]},{"cell_type":"code","execution_count":185,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:19:00.844453Z","iopub.status.busy":"2024-08-08T17:19:00.844139Z","iopub.status.idle":"2024-08-08T17:19:00.855225Z","shell.execute_reply":"2024-08-08T17:19:00.854226Z","shell.execute_reply.started":"2024-08-08T17:19:00.844426Z"},"trusted":true},"outputs":[],"source":["class CrossEntropyLoss:\n","    def forward(self, targets, predictions):\n","        \"\"\"\n","        Perform the forward pass of the Cross-Entropy Loss function.\n","\n","        Args:\n","            targets (np.ndarray): True labels, one-hot encoded, of shape (batch_size, num_classes).\n","            predictions (np.ndarray): Predicted probabilities, of shape (batch_size, num_classes).\n","\n","        Returns:\n","            float: The computed cross-entropy loss.\n","        \"\"\"\n","        # Ensure numerical stability by subtracting the max value from predictions\n","        p_max = np.max(predictions, axis=1, keepdims=True)\n","        exps = np.exp(predictions - p_max)\n","        self.softmax = exps / np.sum(exps, axis=1, keepdims=True)\n","        self.targets = targets\n","\n","        # Compute the loss using the cross-entropy formula\n","        batch_size = predictions.shape[0]\n","        self.loss = -np.sum(targets * np.log(self.softmax + 1e-10)) / batch_size  # Add epsilon for numerical stability\n","        return self.loss\n","\n","    def backward(self):\n","        \"\"\"\n","        Perform the backward pass of the Cross-Entropy Loss function to compute gradients.\n","\n","        Returns:\n","            np.ndarray: Gradient of the loss with respect to the predictions, of shape (batch_size, num_classes).\n","        \"\"\"\n","        batch_size = self.targets.shape[0]\n","        # Compute gradient of the loss with respect to the predictions\n","        d_predictions = (self.softmax - self.targets) / batch_size\n","        return d_predictions\n","\n"]},{"cell_type":"code","execution_count":186,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:19:00.857241Z","iopub.status.busy":"2024-08-08T17:19:00.856812Z","iopub.status.idle":"2024-08-08T17:19:00.872458Z","shell.execute_reply":"2024-08-08T17:19:00.871300Z","shell.execute_reply.started":"2024-08-08T17:19:00.857212Z"},"trusted":true},"outputs":[],"source":["class SGD:\n","    def __init__(self, learning_rate):\n","        \"\"\"\n","        Initialize the Stochastic Gradient Descent (SGD) optimizer.\n","\n","        Args:\n","            learning_rate (float): Learning rate for the optimizer.\n","        \"\"\"\n","        self.learning_rate = learning_rate\n","\n","    def step(self, layers):\n","        \"\"\"\n","        Perform a single optimization step by updating the weights and biases of the given layers.\n","\n","        Args:\n","            layers (list of objects): List of layers in the network. Each layer should have attributes\n","            `W` (weights), `b` (biases), `dW` (gradient of weights), and `db` (gradient of biases).\n","\n","        This method iterates over each layer and updates its weights and biases using the computed gradients.\n","        \"\"\"\n","        for layer in layers:\n","            if hasattr(layer, 'W') and hasattr(layer, 'dW'):\n","                # Update weights and biases for layers with weight and bias attributes\n","                layer.W -= self.learning_rate * layer.dW\n","                layer.b -= self.learning_rate * layer.db\n","\n","class one_hot:\n","    def __init__(self,num_classes):\n","        self.num_classes=num_classes\n","        \n","    \n","    def one_hot_to_label(self,one_hot_matrix):\n","        \"\"\"\n","        Convert a one-hot encoded matrix to class labels.\n","\n","        Args:\n","            y_one_hot (np.ndarray): One-hot encoded array of shape (num_samples, num_classes).\n","\n","        Returns:\n","            np.ndarray: Array of class labels of shape (num_samples,).\n","        \"\"\"\n","        return np.argmax(one_hot_matrix, axis=1)\n","\n","    def convert_to_one_hot(self,vector):\n","        \"\"\"\n","        Convert a vector of integer class labels to one-hot encoded format.\n","\n","        Args:\n","            vector (np.ndarray): 1-D array of integer class labels, shape (num_samples,).\n","            num_classes (int, optional): Number of classes. If None, it is set to the maximum value in the vector + 1.\n","\n","        Returns:\n","            np.ndarray: 2-D array of one-hot encoded labels, shape (num_samples, num_classes).\n","        \"\"\"\n","        result = np.zeros((len(vector), self.num_classes), dtype=int)\n","        result[np.arange(len(vector)), vector] = 1\n","        return result\n","  "]},{"cell_type":"code","execution_count":187,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:19:00.874807Z","iopub.status.busy":"2024-08-08T17:19:00.874377Z","iopub.status.idle":"2024-08-08T17:19:00.895132Z","shell.execute_reply":"2024-08-08T17:19:00.893867Z","shell.execute_reply.started":"2024-08-08T17:19:00.874767Z"},"trusted":true},"outputs":[],"source":["class Model:\n","    def __init__(self):\n","        \"\"\"\n","        Initialize the Model class.\n","        This class manages the layers, loss function, and optimizer for training and inference.\n","        \"\"\"\n","        self.layers = []\n","\n","    def add_layer(self, layer):\n","        \"\"\"\n","        Add a layer to the model.\n","\n","        Args:\n","            layer (object): A layer object that has `forward` and `backward` methods. The layer should \n","                            also have attributes like `W` and `b` if it contains learnable parameters.\n","        \"\"\"\n","        self.layers.append(layer)\n","\n","    def compile(self, loss, optimizer):\n","        \"\"\"\n","        Compile the model by specifying the loss function and optimizer.\n","\n","        Args:\n","            loss (object): An instance of a loss class that has `forward` and `backward` methods.\n","            optimizer (object): An instance of an optimizer class that has a `step` method.\n","        \"\"\"\n","        self.loss = loss\n","        self.optimizer = optimizer\n","\n","    def forward(self, X):\n","        \"\"\"\n","        Perform a forward pass through the model.\n","\n","        Args:\n","            X (np.ndarray): Input data of shape (batch_size, ...).\n","\n","        Returns:\n","            np.ndarray: The output of the model after passing through all layers.\n","        \"\"\"\n","        for layer in self.layers:\n","            X = layer.forward(X)\n","        return X\n","\n","    def backward(self, dA):\n","        \"\"\"\n","        Perform a backward pass through the model to compute gradients.\n","\n","        Args:\n","            dA (np.ndarray): Gradient of the loss with respect to the model's output.\n","\n","        Returns:\n","            None: The method updates the gradients of the layers in place.\n","        \"\"\"\n","        for layer in reversed(self.layers):\n","            dA = layer.backward(dA)\n","\n","    def train(self, X, y, epochs, batch_size):\n","        \"\"\"\n","        Train the model using mini-batch gradient descent.\n","\n","        Args:\n","            X (np.ndarray): Training data of shape (num_samples, ...).\n","            y (np.ndarray): True labels, one-hot encoded, of shape (num_samples, num_classes).\n","            epochs (int): Number of training epochs.\n","            batch_size (int): Size of each mini-batch.\n","        \"\"\"\n","        num_samples = X.shape[0]\n","        for epoch in range(epochs):\n","            for i in range(0, num_samples, batch_size):\n","                X_batch = X[i:i+batch_size]\n","                y_batch = y[i:i+batch_size]\n","\n","                # Forward pass\n","                y_pred = self.forward(X_batch)\n","\n","                # Compute loss\n","                loss = self.loss.forward(y_batch, y_pred)\n","\n","                # Backward pass\n","                dA = self.loss.backward()\n","                self.backward(dA)\n","\n","                # Update weights and biases\n","                self.optimizer.step(self.layers)\n","\n","            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}')\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Make predictions using the trained model.\n","\n","        Args:\n","            X (np.ndarray): Input data of shape (num_samples, ...).\n","\n","        Returns:\n","            np.ndarray: Predicted probabilities of shape (num_samples, num_classes).\n","        \"\"\"\n","        return self.forward(X)\n","\n","    def evaluate(self, X, y):\n","        \"\"\"\n","        Evaluate the model on a test set.\n","\n","        Args:\n","            X (np.ndarray): Test data of shape (num_samples, ...).\n","            y (np.ndarray): True labels, one-hot encoded, of shape (num_samples, num_classes).\n","\n","        Returns:\n","            tuple: A tuple containing:\n","                - np.ndarray: Predicted probabilities of shape (num_samples, num_classes).\n","                - float: Loss value on the test set.\n","                - float: Accuracy percentage on the test set.\n","        \"\"\"\n","        y_pred = self.predict(X)\n","        loss = self.loss.forward(y, y_pred)\n","        accuracy = np.mean(np.argmax(y_pred, axis=1) == np.argmax(y, axis=1)) * 100\n","        return y_pred, loss, accuracy\n","\n","    def save(self, path):\n","        \"\"\"\n","        Save the model to a file.\n","\n","        Args:\n","            path (str): Path to the file where the model will be saved.\n","        \"\"\"\n","        with open(path, 'wb') as file:\n","            pickle.dump(self, file)\n","\n","    def load(path):\n","        \"\"\"\n","        Load a model from a file.\n","\n","        Args:\n","            path (str): Path to the file where the model is saved.\n","\n","        Returns:\n","            Model: The loaded model.\n","        \"\"\"\n","        with open(path, 'rb') as file:\n","            return pickle.load(file)\n"]},{"cell_type":"code","execution_count":188,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:19:00.898432Z","iopub.status.busy":"2024-08-08T17:19:00.898060Z","iopub.status.idle":"2024-08-08T17:19:52.880006Z","shell.execute_reply":"2024-08-08T17:19:52.878808Z","shell.execute_reply.started":"2024-08-08T17:19:00.898386Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20, Loss: 1.9278\n","Epoch 2/20, Loss: 1.8618\n","Epoch 3/20, Loss: 1.8317\n","Epoch 4/20, Loss: 1.8127\n","Epoch 5/20, Loss: 1.8013\n","Epoch 6/20, Loss: 1.7943\n","Epoch 7/20, Loss: 1.7897\n","Epoch 8/20, Loss: 1.7868\n","Epoch 9/20, Loss: 1.7848\n","Epoch 10/20, Loss: 1.7834\n","Epoch 11/20, Loss: 1.7824\n","Epoch 12/20, Loss: 1.7816\n","Epoch 13/20, Loss: 1.7810\n","Epoch 14/20, Loss: 1.7806\n","Epoch 15/20, Loss: 1.7801\n","Epoch 16/20, Loss: 1.7797\n","Epoch 17/20, Loss: 1.7793\n","Epoch 18/20, Loss: 1.7789\n","Epoch 19/20, Loss: 1.7785\n","Epoch 20/20, Loss: 1.7780\n","Test Loss: 1.7121698606004518, Test Accuracy: 75.30952380952381\n","Epoch 1/20, Loss: 1.8155\n","Epoch 2/20, Loss: 1.8145\n","Epoch 3/20, Loss: 1.8130\n","Epoch 4/20, Loss: 1.8114\n","Epoch 5/20, Loss: 1.8097\n","Epoch 6/20, Loss: 1.8080\n","Epoch 7/20, Loss: 1.8064\n","Epoch 8/20, Loss: 1.8050\n","Epoch 9/20, Loss: 1.8035\n","Epoch 10/20, Loss: 1.8021\n","Epoch 11/20, Loss: 1.8006\n","Epoch 12/20, Loss: 1.7992\n","Epoch 13/20, Loss: 1.7977\n","Epoch 14/20, Loss: 1.7962\n","Epoch 15/20, Loss: 1.7946\n","Epoch 16/20, Loss: 1.7930\n","Epoch 17/20, Loss: 1.7914\n","Epoch 18/20, Loss: 1.7899\n","Epoch 19/20, Loss: 1.7884\n","Epoch 20/20, Loss: 1.7868\n","Test Loss: 1.6900401526800881, Test Accuracy: 77.5952380952381\n"]}],"source":["model = Model()\n","model.add_layer(Linear(784, 128))\n","model.add_layer(ReLU())\n","model.add_layer(Linear(128, 10))\n","model.add_layer(Softmax())\n","\n","\n","loss = CrossEntropyLoss()\n","optimizer = SGD(learning_rate=.01)\n","model.compile(loss, optimizer)\n","one_hot=one_hot(10)\n","\n","y_train_one_hot=one_hot.convert_to_one_hot(y_train)\n","y_test_one_hot=one_hot.convert_to_one_hot(y_test)\n","# Assume x_train, y_train, x_test, y_test are preprocessed and available\n","model.train(x_train, y_train_one_hot, epochs=20, batch_size=64)\n","\n","test_array,test_loss, test_accuracy = model.evaluate(x_test, y_test_one_hot)\n","print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n","model.train(x_test,y_test_one_hot,epochs=20,batch_size=42)\n","test_array,test_loss, test_accuracy  = model.evaluate(x_test, y_test_one_hot)\n","print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n","test_array=model.predict(test)\n","y_ans=one_hot.one_hot_to_label(test_array)\n","ans=pd.DataFrame({\n","    'ImageId':submission[\"ImageId\"].to_numpy(),\n","    'Label':y_ans\n","})"]},{"cell_type":"code","execution_count":189,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:19:52.882801Z","iopub.status.busy":"2024-08-08T17:19:52.881922Z","iopub.status.idle":"2024-08-08T17:19:52.896839Z","shell.execute_reply":"2024-08-08T17:19:52.895728Z","shell.execute_reply.started":"2024-08-08T17:19:52.882754Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ImageId</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27995</th>\n","      <td>27996</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>27996</th>\n","      <td>27997</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>27997</th>\n","      <td>27998</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>27998</th>\n","      <td>27999</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>27999</th>\n","      <td>28000</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>28000 rows × 2 columns</p>\n","</div>"],"text/plain":["       ImageId  Label\n","0            1      2\n","1            2      5\n","2            3      9\n","3            4      7\n","4            5      3\n","...        ...    ...\n","27995    27996      9\n","27996    27997      7\n","27997    27998      3\n","27998    27999      9\n","27999    28000      2\n","\n","[28000 rows x 2 columns]"]},"execution_count":189,"metadata":{},"output_type":"execute_result"}],"source":["ans"]},{"cell_type":"code","execution_count":190,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:19:52.899499Z","iopub.status.busy":"2024-08-08T17:19:52.898710Z","iopub.status.idle":"2024-08-08T17:19:52.948289Z","shell.execute_reply":"2024-08-08T17:19:52.947074Z","shell.execute_reply.started":"2024-08-08T17:19:52.899456Z"},"trusted":true},"outputs":[],"source":["ans.to_csv('/kaggle/working/submission.csv',index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":861823,"sourceId":3004,"sourceType":"competition"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
